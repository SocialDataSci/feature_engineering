{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What Algorithm to choose?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![alt text](./img/cheat_sheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](./img/nuclear.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# XGBoost. The very best there is. When you absolutely, positively got to forecast everything in the room, accept no substitutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The XGBoost Advantage\n",
    "\n",
    "### Regularization:\n",
    "Standard GBM implementation has no regularization like XGBoost, therefore it also helps to reduce overfitting.\n",
    "### Parallel Processing:\n",
    "XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "XGBoost also supports implementation on Hadoop.\n",
    "### High Flexibility\n",
    "XGBoost allow users to define custom optimization objectives and evaluation criteria.\n",
    "### Handling Missing Values\n",
    "XGBoost has an in-built routine to handle missing values.\n",
    "### Tree Pruning:\n",
    "A GBM would stop splitting a node when it encounters a negative loss in the split. XGBoost on the other hand make splits upto the max_depth specified and then start pruning the tree backwards and remove splits beyond which there is no positive gain.\n",
    "### Built-in Cross-Validation\n",
    "XGBoost allows user to run a cross-validation at each iteration of the boosting process and thus it is easy to get the exact optimum number of boosting iterations in a single run.\n",
    "\n",
    "###### Courtesy of AARSHAY JAIN \n",
    "###### https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager \n",
    "path = \"/Users/dreyco676/.jupyter/nbconfig\" \n",
    "cm = BaseJSONConfigManager(config_dir=path)\n",
    "cm.update('livereveal', { 'scroll': True, 'width': 1280, 'height': 960,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Import Feature Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# read data in\n",
    "df = pd.read_csv('ml_ready_data.csv', index_col='Unnamed: 0', low_memory=False)\n",
    "# CSVs are dumb, sometimes need to force things to numeric\n",
    "cols = df.columns\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What do we have for variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building your first Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](./img/dependent-vs-independent-variable1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# select X & Y\n",
    "y = 'SalesClosePrice'\n",
    "feature_names = list(df.columns.values)\n",
    "feature_names.remove(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split Data into Test & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df[feature_names], df[y], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![alt text](./img/train-test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# keep labels on test/train\n",
    "X_train = pd.DataFrame(data=Xtrain, columns=feature_names)\n",
    "Xtest = pd.DataFrame(data=Xtest, columns=feature_names)\n",
    "\n",
    "dtrain = xgb.DMatrix(Xtrain, label=ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fit the Model to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(n_jobs=4)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluating your model, what Metrics to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* metrics.explained_variance_score(y_true, y_pred)\t\n",
    "    * Explained variance regression score function\n",
    "\n",
    "\n",
    "* metrics.mean_absolute_error(y_true, y_pred)\t       \n",
    "    * Mean absolute error regression loss\n",
    "\n",
    "* metrics.mean_squared_error(y_true, y_pred[, …])\t    \n",
    "    * Mean squared error regression loss\n",
    "\n",
    "\n",
    "* metrics.mean_squared_log_error(y_true, y_pred)\t    \n",
    "    * Mean squared logarithmic error regression loss\n",
    "\n",
    "\n",
    "* metrics.median_absolute_error(y_true, y_pred)\t    \n",
    "    * Median absolute error regression loss\n",
    "\n",
    "\n",
    "* metrics.r2_score(y_true, y_pred[, …])\t            \n",
    "    * R^2 (coefficient of determination) regression score function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First evaluate your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "ypred = model.predict(Xtest)\n",
    "predictions = [round(value) for value in ypred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# R^2 Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "r2_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RMSE Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(ytest, ypred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Difference between R^2 and RMSE?\n",
    "\n",
    "Both indicate the goodness of the fit.\n",
    "\n",
    "R-squared is conveniently scaled between 0 and 1, whereas RMSE is not scaled to any particular values. This can be good or bad; obviously R-squared can be more easily interpreted, but with RMSE we explicitly know how much our predictions deviate, on average, from the actual values in the dataset. So in a way, RMSE tells you more.\n",
    "\n",
    "###### user3796494\n",
    "###### https://stats.stackexchange.com/questions/142248/difference-between-r-square-and-rmse-in-linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tuning Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'subsample': [1], 'colsample_bytree': [1], 'gamma':[0], \n",
    "                     'learning_rate':[0.1,], 'max_depth': [4, 5, 6], \n",
    "                     'min_child_weight': [0.1, 0.5, 0.75]}]\n",
    "\n",
    "\n",
    "print(\"# Tuning hyper-parameters for r2\")\n",
    "print()\n",
    "\n",
    "model = GridSearchCV(xgb.XGBRegressor(n_jobs=4), tuned_parameters, cv=5, scoring='r2')\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(model.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = model.cv_results_['mean_test_score']\n",
    "stds = model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now we can explore the 'best' model we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = xgb.XGBRegressor(max_depth=5, min_child_weight=0.1, n_jobs=4)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Make predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "ypred = model.predict(Xtest)\n",
    "predictions = [round(value) for value in ypred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(ytest, ypred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# feature importance\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "plot_importance(model, color='red', grid=False, show_values=False, ax=ax)\n",
    "plt.title('importance', fontsize = 36)\n",
    "plt.yticks(fontsize = 18)\n",
    "plt.ylabel('features', fontsize = 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What can we afford to lose?\n",
    "\n",
    "* Too many variables can slow run time of model\n",
    "* Can hamper explainability\n",
    "* May be hard to curate\n",
    "* May not be reported in a timely manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# fit model on all training data\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(Xtrain, ytrain)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "r2 = r2_score(ytest, predictions)\n",
    "print(\"r2: %.2f%%\" % (r2))\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(Xtrain)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier()\n",
    "    selection_model.fit(select_X_train, ytrain)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(Xtest)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, r2: %.2f%%\" % (thresh, select_X_train.shape[1], r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What if we want to answer a different question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# del df['listing_to_median_ratio']\n",
    "# del df['listing_price_per_SQFT']\n",
    "# del df['OriginalListPrice']\n",
    "# prep X & Y\n",
    "y = 'SalesClosePrice'\n",
    "feature_names = list(df.columns.values)\n",
    "feature_names.remove(y)\n",
    "# split data into train and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df[feature_names], df[y], test_size=0.5)\n",
    "# fit model no training data\n",
    "model = xgb.XGBRegressor(max_depth=5, min_child_weight=0.1, n_jobs=4)\n",
    "model.fit(Xtrain, ytrain)\n",
    "# make predictions for test data\n",
    "ypred = model.predict(Xtest)\n",
    "predictions = [round(value) for value in ypred]\n",
    "mse = mean_squared_error(ytest, ypred)\n",
    "rmse = sqrt(mse)\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
